{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3649b8bd-5a60-465a-ac81-dd599d0e1109",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9ab0020-d7d3-4fc7-838a-bf017e410674",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ACC_DIR = Path(\"/Workspace/Users/rkoopal@deloitte.nl/accuracies\")\n",
    "IMAGE_DIR = Path(\"/Workspace/Users/rkoopal@deloitte.nl/images\")\n",
    "\n",
    "TASKS = ['sib200', 'xnli', 'wikiann']\n",
    "OVERWRITE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f55f3ef-b7e0-4f07-86c8-62bb5cb83331",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_df(\n",
    "    task,\n",
    "    data_dir = ACC_DIR,\n",
    "    overwrite = True,\n",
    "    df = None\n",
    "):\n",
    "    if not df:\n",
    "        df = pd.DataFrame()\n",
    "    for file in data_dir.iterdir():\n",
    "        print(file)\n",
    "        if not file.is_file():\n",
    "            continue\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            accuracies = json.load(f)\n",
    "        model = str(file.stem).replace(\"_accuracies\", \"\")\n",
    "        task_scores = accuracies.get(task, None)\n",
    "        if task_scores is None:\n",
    "            continue\n",
    "        if not model in df.index or overwrite:\n",
    "            for lang, scores in task_scores.items():\n",
    "                    df.loc[model, lang] = scores['accuracy']\n",
    "    \n",
    "    df.index = df.index.map(strip_name)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0525e9d0-6f9a-4b26-bcd1-5c7573227416",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.lines as mlines\n",
    "def extract_languages(model_name):\n",
    "    # This function will extract language codes using regex, assuming the format includes '_xx-'\n",
    "    # where 'xx' represents the two-letter language code.\n",
    "    matches = re.findall(r'_([a-z]{2})-', model_name)\n",
    "    return matches[:2]  # Return the first two matches, which should be the relevant languages\n",
    "\n",
    "def plot_kiviat(\n",
    "    df,\n",
    "    lower_bound = 0,\n",
    "    upper_bound = 1,\n",
    "    title = \"title\",\n",
    "    fill = False,\n",
    "    colors = None,\n",
    "    dots = True,\n",
    "    image_dir = IMAGE_DIR,\n",
    "    name = None\n",
    "):\n",
    "    categories = list(df.columns)\n",
    "    N = len(categories)\n",
    "\n",
    "    # What will be the angle of each axis in the plot? (divide the plot / number of variable)\n",
    "    angles = [n / float(N) * 2 * 3.14159 for n in range(N)]\n",
    "    angles += angles[:1]  # to close the loop\n",
    "\n",
    "    # The plot is a circle, so we need to make sure the figure is a square\n",
    "    fig, ax = plt.subplots(figsize=(8, 10), subplot_kw=dict(polar=True))\n",
    "\n",
    "    # Draw one axe per variable and add labels\n",
    "    plt.xticks(angles[:-1], categories)\n",
    "    ax.set_ylim(lower_bound, upper_bound)  # Setting the limits from 0 to 1\n",
    "\n",
    "    if colors is None:\n",
    "        cmap = plt.get_cmap(colors)\n",
    "        colors = cmap(np.linspace(0, 1, len(df.columns)))\n",
    "    else:\n",
    "        colors = plt.cm.viridis(np.linspace(0, 1, len(df)))  # Generate colors\n",
    "\n",
    "\n",
    "    # Plot data for each entity\n",
    "    for i, (idx, row) in enumerate(df.iterrows()):\n",
    "        values = row.tolist()\n",
    "        values += values[:1]  # Close the loop\n",
    "        ax.plot(angles, values, linewidth=1, linestyle='solid', label=idx, color=colors[i])\n",
    "        if fill:\n",
    "            ax.fill(angles, values, alpha=0.1, color=colors[i])\n",
    "\n",
    "        for label, angle_rad in zip(ax.get_xticklabels(), angles[:-1]):\n",
    "            if angle_rad <= np.pi / 2 or angle_rad >= 3 * np.pi / 2:\n",
    "                label.set_horizontalalignment(\"left\")\n",
    "            else:\n",
    "                label.set_horizontalalignment(\"right\")\n",
    "            # Adjust the vertical alignment as well\n",
    "            label.set_verticalalignment(\"bottom\" if angle_rad < np.pi else \"top\")\n",
    "\n",
    "\n",
    "         # Plot dots on specified categories if they appear in the row index\n",
    "        if dots:\n",
    "            for cat_index, cat in enumerate(categories):\n",
    "                languages = extract_languages(cat)\n",
    "                lang1, lang2 = languages[0], languages[1]\n",
    "                if idx == lang1:  # Check if the category appears in the model name\n",
    "                    angle = angles[cat_index]\n",
    "                    value = values[cat_index]\n",
    "                    ax.plot(angle, value, 'o', color='red', markersize=4)  # Plot a red dot\n",
    "                if idx == lang2:  # Check if the category appears in the model name\n",
    "                    angle = angles[cat_index]\n",
    "                    value = values[cat_index]\n",
    "                    ax.plot(angle, value, 'o', color='blue', markersize=4)  # Plot a red dot\n",
    "\n",
    "    # Add a title and a legend\n",
    "    plt.title(title, size=15, color='black', y=1.1)\n",
    "    plt.tight_layout()\n",
    "        # Initial legend from existing lines\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    \n",
    "    # Custom legend entries for specific tasks with red dots\n",
    "    lang_task1_legend = mlines.Line2D([], [], color='red', marker='o', linestyle='None', markersize=4, label='Language task 1')\n",
    "    lang_task2_legend = mlines.Line2D([], [], color='blue', marker='o', linestyle='None', markersize=4, label='Language task 2')\n",
    "    \n",
    "    # Combine original legend handles with custom ones\n",
    "    if dots:\n",
    "        handles.extend([lang_task1_legend, lang_task2_legend])\n",
    "\n",
    "    # Display the combined legend\n",
    "    ax.legend(handles=handles, loc='upper right', bbox_to_anchor=(-0.1, 0))\n",
    "\n",
    "    if name:\n",
    "        plt.savefig(image_dir / name, bbox_inches='tight')  # Save the figure to the file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "ba52167f-4de1-48b5-bf31-56201a546884",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# def plot_bar_charts(dataframes, labels, average_axis=1, xlabel='Languages', ylabel='Accuracy', title='Title', squish=1):\n",
    "#     \"\"\"\n",
    "#     Plots comparison bar charts of multiple dataframes with customization options.\n",
    "#     Bars are grouped together based on the 'squish' parameter, and each dataframe is represented by a consistent color.\n",
    "#     A small gap is maintained between each group.\n",
    "\n",
    "#     Parameters:\n",
    "#         dataframes (list of pd.DataFrame): List of dataframes to plot.\n",
    "#         labels (list of str): Labels for each dataframe, used for the legend.\n",
    "#         average_axis (int): Axis to compute the average (0 for models, 1 for languages).\n",
    "#         xlabel (str): Label for the x-axis.\n",
    "#         ylabel (str): Label for the y-axis.\n",
    "#         title (str): Title of the plot.\n",
    "#         squish (int): Number of models to group together.\n",
    "#     \"\"\"\n",
    "#     if len(dataframes) != len(labels):\n",
    "#         raise ValueError(\"Each dataframe must have a corresponding label.\")\n",
    "\n",
    "#     # Combine all labels from the dataframes\n",
    "#     all_labels = pd.Index([])\n",
    "#     for df in dataframes:\n",
    "#         all_labels = all_labels.union(df.columns if average_axis == 0 else df.index)\n",
    "\n",
    "#     # Calculate the average for each dataframe and reindex to include all labels\n",
    "#     averages = [df.mean(axis=average_axis).reindex(all_labels, fill_value=0) for df in dataframes]\n",
    "\n",
    "#     # Creating a figure and a set of subplots\n",
    "#     fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "#     # The total number of groups\n",
    "#     num_groups = (len(all_labels) + squish - 1) // squish\n",
    "\n",
    "#     # Set up bar width and base indices\n",
    "#     base_width = 0.8 / squish\n",
    "#     group_spacing = 0.1  # Additional spacing between groups\n",
    "#     indices = np.arange(0, num_groups * squish * (base_width + group_spacing), squish * (base_width + group_spacing))\n",
    "\n",
    "#     # Plotting each dataframe\n",
    "#     for i, (avg, label) in enumerate(zip(averages, labels)):\n",
    "#         for j in range(0, len(all_labels), squish):\n",
    "#             group_labels = all_labels[j:j+squish]\n",
    "#             group_values = avg[j:j+squish]\n",
    "#             group_index = indices[j // squish] + i * base_width\n",
    "#             ax.bar(group_index, group_values, base_width, alpha=0.8, label=label if j == 0 else \"\")\n",
    "\n",
    "#     # Adjusting x-ticks to align with the middle of groups\n",
    "#     ax.set_xticks(indices + (base_width * len(dataframes) / 2) - (base_width / 2))\n",
    "#     ax.set_xticklabels([','.join(all_labels[i:i+squish]) for i in range(0, len(all_labels), squish)], rotation=45, ha='right')\n",
    "\n",
    "#     # Setting labels and title\n",
    "#     ax.set_xlabel(xlabel)\n",
    "#     ax.set_ylabel(ylabel)\n",
    "#     ax.set_title(title)\n",
    "#     ax.legend(handles=[ax.patches[i] for i in range(len(dataframes))], labels=labels)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "\n",
    "#     # Dynamic y-axis limits based on data\n",
    "#     max_y_value = max([avg.max() for avg in averages])\n",
    "#     ax.set_ylim([0, max_y_value * 1.1])\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "# # Example usage as previously defined\n",
    "\n",
    "\n",
    "# def plot_bar_charts(dataframes, labels, average_axis=1, xlabel='Languages', ylabel='Accuracy', title='Title', squish=1):\n",
    "#     \"\"\"\n",
    "#     Plots comparison bar charts of multiple dataframes with customization options.\n",
    "#     Bars are grouped together based on the 'squish' parameter, ensuring even group distribution.\n",
    "\n",
    "#     Parameters:\n",
    "#         dataframes (list of pd.DataFrame): List of dataframes to plot.\n",
    "#         labels (list of str): Labels for each dataframe, used for the legend.\n",
    "#         average_axis (int): Axis to compute the average (0 for models, 1 for languages).\n",
    "#         xlabel (str): Label for the x-axis.\n",
    "#         ylabel (str): Label for the y-axis.\n",
    "#         title (str): Title of the plot.\n",
    "#         squish (int): Number of models to group together.\n",
    "#     \"\"\"\n",
    "#     if len(dataframes) != len(labels):\n",
    "#         raise ValueError(\"Each dataframe must have a corresponding label.\")\n",
    "\n",
    "#     # Combine all labels from the dataframes\n",
    "#     all_labels = pd.Index([])\n",
    "#     for df in dataframes:\n",
    "#         all_labels = all_labels.union(df.columns if average_axis == 0 else df.index)\n",
    "\n",
    "#     # Calculate the average for each dataframe and reindex to include all labels\n",
    "#     averages = [df.mean(axis=average_axis).reindex(all_labels, fill_value=0) for df in dataframes]\n",
    "\n",
    "#     # Creating a figure and a set of subplots\n",
    "#     fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "#     # The total number of groups\n",
    "#     num_groups = (len(all_labels) + squish - 1) // squish  # This handles incomplete groups\n",
    "\n",
    "#     # Set up bar width and base indices\n",
    "#     base_width = 0.5 / squish\n",
    "#     indices = np.arange(0, num_groups * squish, squish)  # Indices for each group start\n",
    "\n",
    "#     # Plotting each dataframe\n",
    "#     for i, avg in enumerate(averages):\n",
    "#         # Compute individual bar positions\n",
    "#         for j in range(0, len(all_labels), squish):\n",
    "#             group_labels = all_labels[j:j+squish]\n",
    "#             group_values = avg[j:j+squish]\n",
    "#             group_index = indices[j // squish] + i * base_width\n",
    "#             ax.bar(group_index, group_values, base_width, alpha=0.8, label=labels[i] if j == 0 else \"\")\n",
    "\n",
    "#     # Adjusting x-ticks to align with the middle of groups\n",
    "#     ax.set_xticks(indices + base_width * len(dataframes) / 2 - base_width / 2)\n",
    "#     ax.set_xticklabels([','.join(all_labels[i:i+squish]) for i in range(0, len(all_labels), squish)], rotation=45, ha='right')\n",
    "\n",
    "#     # Setting labels and title\n",
    "#     ax.set_xlabel(xlabel)\n",
    "#     ax.set_ylabel(ylabel)\n",
    "#     ax.set_title(title)\n",
    "#     ax.legend()\n",
    "\n",
    "#     plt.tight_layout()\n",
    "\n",
    "#     # Dynamic y-axis limits based on data\n",
    "#     max_y_value = max([avg.max() for avg in averages])\n",
    "#     ax.set_ylim([0, max_y_value * 1.1])\n",
    "\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc6574a3-ab18-4ece-9163-52937df0d5d4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_bar_chart(dfs, df_names, agg_func=None, title='Grouped Bar Chart', ylabel='Values', xlabel='Categories', rotate_xticks=False):\n",
    "    \"\"\"\n",
    "    Creates a grouped bar chart for given dataframes.\n",
    "    \n",
    "    Parameters:\n",
    "    - dfs: List of pandas DataFrames.\n",
    "    - df_names: List of names corresponding to each DataFrame for legend.\n",
    "    - agg_func: Function used to aggregate data. If None, data is not aggregated.\n",
    "    - title: Title of the plot.\n",
    "    - ylabel: Y-axis label.\n",
    "    - xlabel: X-axis label.\n",
    "    - rotate_xticks: Boolean, set to True to rotate x-axis labels for better readability.\n",
    "    \n",
    "    Returns:\n",
    "    - A matplotlib bar chart.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Aggregate data if an aggregation function is provided\n",
    "    if agg_func is not None:\n",
    "        dfs = [df.agg(agg_func, axis=0) for df in dfs]\n",
    "    \n",
    "    # Number of groups and bar width\n",
    "    n_groups = dfs[0].shape[0]\n",
    "    n_dfs = len(dfs)\n",
    "    bar_width = 0.8 / n_dfs\n",
    "    index = np.arange(n_groups)\n",
    "    \n",
    "    # Create a bar for each DataFrame\n",
    "    fig, ax = plt.subplots()\n",
    "    for i, df in enumerate(dfs):\n",
    "        means = df.mean(axis=1)\n",
    "        std = df.std(axis=1)\n",
    "        ax.bar(index + i * bar_width, means, bar_width, yerr=std, label=df_names[i])\n",
    "    \n",
    "    # Adding labels and title\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(index + bar_width * (n_dfs - 1) / 2)\n",
    "    ax.set_xticklabels(dfs[0].index)\n",
    "    ax.legend()\n",
    "    \n",
    "    # Rotate xticks if specified\n",
    "    plt.xticks(rotation=45, ha='right')  # 'ha' aligns the labels to the right for better readability\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcc53776-457a-4c1b-bb40-e218254a40f6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def strip_name(\n",
    "    name,\n",
    "    model=True,\n",
    "    ft = True,\n",
    "    merging=False    \n",
    "):\n",
    "\n",
    "    # Remove model, feature type, and merge types as initially intended\n",
    "    if model:\n",
    "        name = name.replace(\"mt0-large--\", \"base--\")\n",
    "        name = name.replace(\"mt0-large_\", \"\")\n",
    "    if ft:\n",
    "        name = name.replace(\"ft_\", \"\")\n",
    "    if merging:\n",
    "        name = name.replace(\"mono\", \"\")\n",
    "        name = name.replace(\"pooling\", \"\")\n",
    "    \n",
    "    # Explicitly remove undesired characters at the beginning and end of the string\n",
    "    name = name.strip(\"-_\")\n",
    "\n",
    "    # Finally, strip leading/trailing whitespace and return the modified name\n",
    "    return name.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3426630e-6b55-4aa3-9ad1-02641ae3729b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def filter_models(\n",
    "    df,\n",
    "    terms,   # terms to keep,\n",
    "    contains = all,\n",
    "    out=False\n",
    "):\n",
    "    models = df.index.to_list()\n",
    "    keep_list = []\n",
    "    for term in terms:\n",
    "        keep_list.append([model for model in models if term in model])\n",
    "    \n",
    "    if out:\n",
    "        filtered_df = df[~df.index.to_series().apply(lambda idx: contains(term in idx for term in terms))]\n",
    "    else:\n",
    "        filtered_df = df[df.index.to_series().apply(lambda idx: contains(term in idx for term in terms))]\n",
    "\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "115c29ac-3932-48d3-88cb-ae8aa35e32a2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def method_comparison_data(\n",
    "    dfs,\n",
    "    tasks,\n",
    "    languages = ['ar', 'de', 'el', 'es'],\n",
    "    merging = ['mono'],\n",
    "):\n",
    "    assert len(tasks) < 3, \"tasks cannot be above 2\"\n",
    "\n",
    "    domains = [(task, language) for language in languages for task in tasks]\n",
    "\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    for task, df in zip(tasks, dfs):\n",
    "        task0 = tasks[0]\n",
    "        task1 = tasks[1]\n",
    "        for merge in merging:\n",
    "            for language in languages:\n",
    "                domain_name = \"_\".join([task, language])\n",
    "                \n",
    "                data.loc[f\"base\", domain_name] = df.loc[\"base\", language]\n",
    "\n",
    "                data.loc[f\"base-FT\", domain_name] = df.loc[f\"base--{task}_{language}-{merge}\", language]\n",
    "\n",
    "                data.loc[f\"FT-FT\", domain_name] = df.loc[f\"{task0}_{language}--{task1}_{language}-{merge}\", language]\n",
    "                \n",
    "                data.loc[f\"FT\", domain_name] = df.loc[f\"{task}_{language}\", language]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "409fa765-cd8e-4218-83fc-12688ef0b788",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "test = [1, 2, 3, 4]\n",
    "[t for t in combinations(test, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9ce4fc8-acad-4092-a6ec-e0169f5bef0c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from itertools import combinations_with_replacement, combinations\n",
    "\n",
    "import numpy as np\n",
    "from itertools import combinations_with_replacement\n",
    "\n",
    "def get_CLA(df, task0, task1, merge, language, languages=['ar', 'de', 'el', 'es']):\n",
    "    \"\"\"\n",
    "    Calculate the mean of specific DataFrame values excluding the specified language.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): The DataFrame to process.\n",
    "    - task0 (str): The first task identifier.\n",
    "    - task1 (str): The second task identifier.\n",
    "    - merge (str): The merge strategy.\n",
    "    - language (str): The language to exclude.\n",
    "    - languages (list): List of languages to consider.\n",
    "\n",
    "    Returns:\n",
    "    - float: The calculated mean.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        values = [df.loc[f\"{task0}_{lang1}--{task1}_{lang2}-{merge}\", language] for lang1, lang2 in combinations_with_replacement(languages, 2) if (lang1 == language and lang2 != language) or (lang1 != language and lang2 == language)]\n",
    "        # print(f\"values for {task0} - {task1} - {language} are {values}\")\n",
    "        return np.mean(values)\n",
    "    except KeyError:\n",
    "        print(f\"One or more keys not found in DataFrame for language {language}\")\n",
    "        return np.nan\n",
    "    \n",
    "def method_comparison_data_CLA(\n",
    "    dfs,\n",
    "    tasks,\n",
    "    languages = ['ar', 'de', 'el', 'es'],\n",
    "    merging = ['mono'],\n",
    "):\n",
    "    assert len(tasks) < 3, \"tasks cannot be above 2\"\n",
    "\n",
    "    domains = [(task, language) for language in languages for task in tasks]\n",
    "\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    for task, df in zip(tasks, dfs):\n",
    "        task0 = tasks[0]\n",
    "        task1 = tasks[1]\n",
    "        for merge in merging:\n",
    "            for language in languages:\n",
    "                domain_name = \"_\".join([task, language])\n",
    "                \n",
    "                data.loc[f\"base\", domain_name] = df.loc[\"base\", language]\n",
    "\n",
    "                data.loc[f\"base-FT\", domain_name] = df.loc[f\"base--{task}_{language}-{merge}\", language]\n",
    "\n",
    "                data.loc[f\"FT-FT (WL)\", domain_name] = df.loc[f\"{task0}_{language}--{task1}_{language}-{merge}\", language]\n",
    "\n",
    "                data.loc[f\"FT-FT (WT)\", domain_name] = np.mean([df.loc[f\"{task}_{lang1}--{task}_{lang2}-{merge}\", language] for lang1, lang2 in combinations(languages, 2)])\n",
    "\n",
    "                data.loc[f\"FT-FT (CLA)\", domain_name] = get_CLA(df, task0=task0, task1=task1, merge=merge, language=language)\n",
    "                \n",
    "                data.loc[f\"FT\", domain_name] = df.loc[f\"{task}_{language}\", language]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77112853-2ad8-40d6-941e-5bfe0d7e7440",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "A = 'sib200'\n",
    "B = 'xnli'\n",
    "X = 'de'\n",
    "Y = 'de'\n",
    "langs = ['ar', 'de', 'el', 'es', 'fr', 'ru']\n",
    "domains = [(task, lang) for task in (A, B) for lang in langs]\n",
    "ft_domains = [f\"{A}_{X}\", f\"{B}_{Y}\"]\n",
    "mix_domains = [f\"{A}_{Y}\", f\"{B}_{X}\"]\n",
    "non_domains = [f\"{t}_{l}\" for t, l in domains if f\"{t}_{l}\" not in ft_domains and f\"{t}_{l}\" not in mix_domains]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5315ef04-538b-495d-b709-0d6bdee1fdf7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mix_domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2157afa-5ea7-443f-845b-525a82e044a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_domains(name):\n",
    "    # Extract tasks and language codes from the name using regular expressions\n",
    "    match = re.match(r'(\\w+)_(\\w{2})--(\\w+)_(\\w{2})-.*', name)\n",
    "    if match:\n",
    "        task0 = match.group(1)\n",
    "        lang0 = match.group(2)\n",
    "        task1 = match.group(3)\n",
    "        lang1 = match.group(4)\n",
    "        return task0, task1, lang0, lang1\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def normalize_df(df):\n",
    "    for column in df.columns:\n",
    "        min_val = df[column].min()\n",
    "        max_val = df[column].max()\n",
    "        df[column] = (df[column] - min_val) / (max_val - min_val) if (max_val - min_val) != 0 else 0\n",
    "    return df\n",
    "\n",
    "def target_switch_data(\n",
    "    dfs,\n",
    "    tasks,\n",
    "    languages = ['ar', 'de', 'el', 'es'],\n",
    "    merge = ['mono'],\n",
    "):\n",
    "    assert len(tasks) < 3, \"tasks cannot be above 2\"\n",
    "\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    df1 = filter_models(sib_df, terms=tasks+merge)\n",
    "    df2 = filter_models(xnli_df, terms=tasks+merge)\n",
    "    # Create a set of the union of the two indices of the dfs\n",
    "    # model_names = set(df1.index).union(set(df2.index))\n",
    "    model_names = set(df1.index)\n",
    "    print(model_names)\n",
    "    for model in model_names:\n",
    "        A, B, X, Y = extract_domains(model)\n",
    "        # domains = [(A,X), (B,Y), (A,Y), (B,X)]\n",
    "        domains = [(task, lang) for task in (A, B) for lang in languages]\n",
    "        ft_domains = [f\"{A}_{X}\", f\"{B}_{Y}\"]\n",
    "        mix_domains = [f\"{A}_{Y}\", f\"{B}_{X}\"]\n",
    "        non_domains = [f\"{t}_{l}\" for t, l in domains if f\"{t}_{l}\" not in ft_domains and f\"{t}_{l}\" not in mix_domains]\n",
    "        tmp_df = pd.DataFrame()\n",
    "        for task, lang in domains:\n",
    "            if task == A:\n",
    "                df = dfs[0]\n",
    "            else:\n",
    "                df = dfs[1]\n",
    "            tmp_df.loc[f\"base\", f\"{task}_{lang}\"] = df.loc[\"base\", lang]\n",
    "            tmp_df.loc[f\"FT\", f\"{task}_{lang}\"] = df.loc[f\"{task}_{lang}\", lang]\n",
    "            tmp_df.loc[f\"FT-FT\", f\"{task}_{lang}\"] = df.loc[model, lang]\n",
    "\n",
    "        print(tmp_df)\n",
    "        normalized = normalize_df(tmp_df)\n",
    "        \n",
    "        # Average the columns that fall under ft_domains and mix_domains together after normalizing\n",
    "        ft_avg = normalized[ft_domains].mean(axis=1)\n",
    "        mix_avg = normalized[mix_domains].mean(axis=1)\n",
    "        non_avg = normalized[non_domains].mean(axis=1)\n",
    "        \n",
    "        data.loc[model, 'target-base'] = ft_avg['base']\n",
    "        data.loc[model, 'target-FT'] = ft_avg['FT']\n",
    "        data.loc[model, 'target-FT-FT'] = ft_avg['FT-FT']\n",
    "\n",
    "        data.loc[model, 'switch-base'] = mix_avg['base']\n",
    "        data.loc[model, 'switch-FT'] = mix_avg['FT']\n",
    "        data.loc[model, 'switch-FT-FT'] = mix_avg['FT-FT']\n",
    "\n",
    "        data.loc[model, 'non-base'] = non_avg['base']\n",
    "        data.loc[model, 'non-FT'] = non_avg['FT']\n",
    "        data.loc[model, 'non-FT-FT'] = non_avg['FT-FT']\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc22cf88-8424-44b3-9b71-f913d6686dc8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_bar_split(\n",
    "    df,\n",
    "    groups=[['D_ft-base', 'D_ft-FT', 'D_ft-FT-FT'], ['D_mix-base', 'D_mix-FT', 'D_mix-FT-FT']]\n",
    "):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 6))\n",
    "\n",
    "    # D_ft related columns\n",
    "    df[groups[0]].plot(kind='bar', ax=axes[0], title='D_ft Columns')\n",
    "    axes[0].set_ylabel('Values')\n",
    "    axes[0].set_xticklabels(df.index, rotation=90)\n",
    "\n",
    "    # D_mix related columns\n",
    "    df[groups[1]].plot(kind='bar', ax=axes[1], title='D_mix Columns')\n",
    "    axes[1].set_ylabel('Values')\n",
    "    axes[1].set_xticklabels(df.index, rotation=90)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af4d5674-6176-45e6-9954-08da93166545",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_data(df, show_averages=False, title=None, xlabel='Models', ylabel='Values', xticks_rotation=45, ylim=None, save_path=None, color_map='YlGnBu'):\n",
    "    \"\"\"\n",
    "    Plots a bar chart for the provided DataFrame with options to display averages, customizable labels, configurable y-axis limits, and save the figure to a file.\n",
    "    \n",
    "    Args:\n",
    "    df (pd.DataFrame): DataFrame containing the data to be plotted.\n",
    "    show_averages (bool): If True, plots the average values of the columns. If False, plots individual values.\n",
    "    title (str): Title of the plot.\n",
    "    xlabel (str): Label for the x-axis.\n",
    "    ylabel (str): Label for the y-axis.\n",
    "    xticks_rotation (int): Degrees of rotation for the x-tick labels.\n",
    "    ylim (tuple, optional): A tuple (ymin, ymax) setting the limits of the y-axis.\n",
    "    save_path (str, optional): Path to save the figure. If None, the figure is not saved.\n",
    "    \"\"\"\n",
    "        # Create a colormap instance\n",
    "    cmap = plt.get_cmap(color_map)\n",
    "\n",
    "    # Generate an array of colors from the colormap\n",
    "    colors = cmap(np.linspace(0, 1, len(df.columns)))\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    if show_averages:\n",
    "        df.mean().plot(kind='bar', ax=ax, color=colors)\n",
    "        ax.set_title(title)\n",
    "        ax.set_xticklabels(df.columns, rotation=xticks_rotation)\n",
    "    else:\n",
    "        df.plot(kind='bar', ax=ax, color=colors)\n",
    "        ax.set_title(title)\n",
    "        ax.set_xticklabels(df.index, rotation=xticks_rotation)\n",
    "\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    \n",
    "    if ylim:\n",
    "        ax.set_ylim(ylim)\n",
    "    \n",
    "        # Adjust the legend position\n",
    "    # ax.legend(loc='upper right', bbox_to_anchor=(1, 1), bbox_transform=ax.transAxes)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1.2, 1.2])  # Adjust the overall layout to fit everything neatly\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"Figure saved to {save_path}\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa55c3c0-6504-4624-b26a-84b0358a3a3a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_ft_langs_data(\n",
    "    dfs,\n",
    "    tasks,\n",
    "    langs = ['ar', 'de', 'el', 'es', 'fr', 'ru']\n",
    "):\n",
    "    data = pd.DataFrame()\n",
    "    for task, df in zip(tasks, dfs):\n",
    "        target_langs = []\n",
    "        other_langs = []\n",
    "        for i, row in df.iterrows():\n",
    "            target_lang = str(i).split(\"_\")[1].replace(\"-mono\", \"\")\n",
    "            target_langs.append(df.loc[i, target_lang])\n",
    "            other_langs.append(np.mean([df.loc[i, lang] for lang in langs if lang != target_lang]))\n",
    "            print(f\"For {task} - {target_lang} we have target values: {df.loc[i, target_lang]}\")\n",
    "            print(f\"For {task} - {target_lang} we have non-target values: {[df.loc[i, lang] for lang in langs if lang != target_lang]}\")\n",
    "        data.loc[task, 'Target languages'] = np.mean(target_langs)\n",
    "        data.loc[task, 'Other languages'] = np.mean(other_langs)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def get_cross_langs_data(\n",
    "    dfs,\n",
    "    tasks,\n",
    "    langs = ['ar', 'de', 'el', 'es', 'fr', 'ru']\n",
    "):\n",
    "    data = pd.DataFrame()\n",
    "    for task, df in zip(tasks, dfs):\n",
    "        target_lang_scores = []\n",
    "        other_lang_scores = []\n",
    "        for i, row in df.iterrows():\n",
    "            print(i)\n",
    "            _, _, tl1, tl2 = extract_domains(i)\n",
    "            target_langs = [tl1, tl2]\n",
    "            print(target_langs)\n",
    "            for target_lang in target_langs:\n",
    "                target_lang_scores.append(df.loc[i, target_lang])\n",
    "                other_lang_scores.append(np.mean([df.loc[i, lang] for lang in langs if not lang in target_langs]))\n",
    "                print(f\"For {task} - {target_lang} we have target values: {df.loc[i, target_lang]}\")\n",
    "                print(f\"For {task} - {target_lang} we have non-target values: {[df.loc[i, lang] for lang in langs if lang != target_lang]}\")\n",
    "        data.loc[task, 'Target languages'] = np.mean(target_lang_scores)\n",
    "        data.loc[task, 'Other languages'] = np.mean(other_lang_scores)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22012f25-de4a-45d3-b4c1-e1c476856dab",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a12a3b8d-9496-4930-b3c7-dbabf71132dd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### get dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c4e108c-3afd-4fa0-a022-066089581fde",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#df's \n",
    "xnli_df = get_df('xnli')\n",
    "wiki_df = get_df('wikiann')\n",
    "sib_df = get_df('sib200')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcee35db-da13-4504-af8f-dcaf5af7057c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ft_sib = filter_models(sib_df, terms=['base', 'mono', 'pooling', 'wikiann', 'xnli', 'experiment'], contains=any, out=True)\n",
    "ft_xnli = filter_models(xnli_df, terms=['base', 'mono', 'pooling', 'experiment', 'wikiann', 'sib', 'mt0-large'], contains=any, out=True)\n",
    "ft_wiki = filter_models(wiki_df, terms=['base', 'mono', 'pooling', 'experiment', 'xnli', 'sib'], contains=any, out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40eb703f-b9cb-41a5-847e-9f58cbb37064",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "base_sib = filter_models(sib_df, terms=['base', 'sib', 'mono'], contains=all, out=False)\n",
    "base_xnli = filter_models(xnli_df, terms=['base', 'xnli', 'mono'], contains=all, out=False)\n",
    "base_wikiann = filter_models(wiki_df, terms=['base', 'wiki', 'mono'], contains=all, out=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5d913ca-6111-4a9d-acf8-40952a918ec2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ft_sib_net = ft_sib - sib_df.loc['base']\n",
    "ft_xnli_net = ft_xnli - xnli_df.loc['base']\n",
    "ft_wiki_net = ft_wiki - wiki_df.loc['base']\n",
    "\n",
    "base_sib_net = base_sib - sib_df.loc['base']\n",
    "base_xnli_net = base_xnli - xnli_df.loc['base']\n",
    "base_wiki_net = base_wikiann - wiki_df.loc['base']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff5c683c-b1b7-4e53-84ac-af0bced1a11a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "total = pd.concat([ft_sib_net, ft_xnli_net, ft_wiki_net, base_sib_net, base_xnli_net, base_wiki_net])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a14679d-8216-4ce1-8ab2-e89740119cb1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrames\n",
    "# Replace these with your actual DataFrames: ft_sib_net, ft_xnli_net, ft_wiki_net, base_sib_net, base_xnli_net, base_wiki_net\n",
    "# Assuming they have the same columns\n",
    "\n",
    "# Calculate the mean for each DataFrame\n",
    "ft_sib_net_mean = ft_sib_net.mean().to_frame().T\n",
    "ft_xnli_net_mean = ft_xnli_net.mean().to_frame().T\n",
    "ft_wiki_net_mean = ft_wiki_net.mean().to_frame().T\n",
    "base_sib_net_mean = base_sib_net.mean().to_frame().T\n",
    "base_xnli_net_mean = base_xnli_net.mean().to_frame().T\n",
    "base_wiki_net_mean = base_wiki_net.mean().to_frame().T\n",
    "\n",
    "# Optionally, name the rows for clarity\n",
    "ft_sib_net_mean.index = ['FT_SIB-200']\n",
    "ft_xnli_net_mean.index = ['FT_XNLI']\n",
    "ft_wiki_net_mean.index = ['FT_WikiANN']\n",
    "base_sib_net_mean.index = ['Base--FT_SIB-200']\n",
    "base_xnli_net_mean.index = ['Base--XNLI']\n",
    "base_wiki_net_mean.index = ['Base--WikiANN']\n",
    "\n",
    "# Concatenate the means into a single DataFrame\n",
    "total_mean = pd.concat([ft_sib_net_mean, ft_xnli_net_mean, ft_wiki_net_mean, base_sib_net_mean, base_xnli_net_mean, base_wiki_net_mean])\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(total_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d372d1e5-1d7f-4e83-84ee-0249df6578d7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_data(total_mean, title=\"Accuracy for FT and base merged models presented as net difference with zero-shot scores.\", xlabel=\"Model\", ylabel=\"Accuracy (minus base score)\", save_path= IMAGE_DIR / 'net_diff_ft_base.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b79d9056-c192-43a0-8cde-b66e13a6ccbc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cl_sib = filter_models(filter_models(sib_df, terms=['mono', 'sib']), terms=['base', 'xnli', 'wiki'], contains=any, out=True)\n",
    "cl_xnli = filter_models(filter_models(xnli_df, terms=['mono', 'xnli']), terms=['base', 'sib', 'wiki'], contains=any, out=True)\n",
    "cl_wiki = filter_models(filter_models(wiki_df, terms=['mono', 'wiki']), terms=['base', 'sib', 'xnli'], contains=any, out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acf7e4f2-db13-4879-ac11-1a79c5d426e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "base_data = get_ft_langs_data(dfs=[base_sib, base_xnli, base_wikiann], tasks=['sib200', 'xnli', 'wikiann'])\n",
    "ft_data = get_ft_langs_data(dfs=[ft_sib, ft_xnli, ft_wiki], tasks=['sib200', 'xnli', 'wikiann'])\n",
    "cl_data = get_cross_langs_data([cl_sib, cl_xnli, cl_wiki], tasks=['sib200', 'xnli', 'wikiann'])\n",
    "ct_data = get_cross_langs_data([cl_sib, cl_xnli, cl_wiki], tasks=['sib200', 'xnli', 'wikiann'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53f7d8f4-3033-4dfb-9b3d-172e75dc25bd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### target vs other langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbb0faec-e164-47e9-90c1-fa764f95fc6c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ft_data = ft_data.rename(columns={\"Target languages\": \"Target languages (ft)\", \"Other languages\": \"Other languages (FT)\"})\n",
    "base_data = base_data.rename(columns={\"Target languages\": \"Target languages (base-ft)\", \"Other languages\": \"Other languages (base-FT)\"})\n",
    "cl_data = cl_data.rename(columns={\"Target languages\": \"Target languages (ft-WL)\", \"Other languages\": \"Other languages (FT-WL)\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1496e488-f0f7-4ec8-a046-da161a559141",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "merged_data = pd.concat([ft_data, base_data, cl_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d56498d-173b-4ddd-84e0-ee2bebd866ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "name = IMAGE_DIR / \"base_base_ft-ft_wl-target-scores.png\"\n",
    "# name = None\n",
    "plot_data(merged_data, xticks_rotation=0, ylim=(0, 1.1), ylabel='Accuracy', xlabel='Task', save_path=name, color_map='YlGnBu', title=\"Target vs non-target language performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7c6a8bd-c0d4-489d-ad1a-6f8998236841",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "xnli_df = filter_models(xnli_df, terms=['xnli'])\n",
    "wiki_df = filter_models(xnli_df, terms=['wikiann'])\n",
    "sib_df = filter_models(xnli_df, terms=['sib'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e94de289-d811-4da2-9fd9-f7e610b29c41",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Target vs switched domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df87dab9-c9f1-49ba-a08b-353530ad189b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sib_df_mono = filter_models(sib_df, terms=['mono', 'sib'])\n",
    "xnli_df_mono = filter_models(sib_df, terms=['mono', 'xnli'])\n",
    "wiki_df_mono = filter_models(sib_df, terms=['mono', 'wiki'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "413921bc-b262-44d5-8461-9ce4979196dd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ct_data = target_switch_data([wiki_df, xnli_df], tasks=['sib200', 'xnli'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67f98f6f-5846-4d43-8de4-5e905916ea75",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_data(ct_data[['target-FT-FT', 'switch-FT-FT']], show_averages=False, ylabel=\"Score relative to base and FT scores\", xlabel=\"FT-FT-models\", title=\"Comparison on target and switched domains for Wikiann-SIB200\", save_path= IMAGE_DIR / \"target_switch_comparison_wiki_sib.png\", ylim=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9026ca17-c97f-4b9c-abc7-38e67708c44e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ct_pivot = ct_data[['target-FT-FT', 'switch-FT-FT', 'non-FT-FT']].rename(columns={'target-FT-FT': \"Target domains\", \"switch-FT-FT\" : \"Switched domains\", \"non-FT-FT\": \"Other domains\"}).transpose()\n",
    "ct_pivot.columns = [col.replace(\"-mono\", \"\") for col in ct_pivot.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ba6aa49-56cb-4423-a085-d2bccb08318c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_kiviat(ct_pivot, dots=False, title=\"Cross task peformance FT-FT models on target and switched domains - SIB200 - XNLI\", name=\"ct-perfromance-sib-xnli.png\", colors=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94f8376e-7446-46ba-9da6-0752a32c0c0b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### method comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d81e40d9-4a68-4b6d-a37a-136b65f68864",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "merge='mono'\n",
    "task1 = 'wikiann'\n",
    "task2 = 'sib200'\n",
    "df1 = wiki_df\n",
    "df2 = sib_df\n",
    "\n",
    "# name = f\"method_comparison_{task1}_{task2}_{merge}.png\"\n",
    "cla_name = f\"method_comparison_CLA_{task1}_{task2}_{merge}.png\"\n",
    "# cla_name = None\n",
    "\n",
    "cla_data = method_comparison_data_CLA(dfs=[df1, df2], tasks=[task1, task2], merging=[merge])\n",
    "# data = method_comparison_data(dfs=[df1, df2], tasks=[task1, task2], merging=[merge])\n",
    "plot_kiviat(cla_data, lower_bound=0, upper_bound=1.0, dots=False, title=f\"Method comparison for {task1} and {task2} - {merge} merged\", name=cla_name)\n",
    "# plot_kiviat(data, lower_bound=0, upper_bound=1.0, dots=False, title=f\"Method comparison for {task1} and {task2} - {merge} merged\", name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21988376-a607-4e7f-ad60-e74db6c3b2ec",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### mono - pool comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d21bf163-f086-44c0-80db-362eea8bb6c9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def compare_mono_pool(\n",
    "    df,\n",
    "    task\n",
    "):\n",
    "    mono_df = filter_models(df, terms=['mono', task], contains=all)\n",
    "    pool_df = filter_models(df, terms=['pool', task], contains=all)\n",
    "\n",
    "    assert len(mono_df) == len(pool_df), f\"different lengths {len(mono_df)}, {len(pool_df)}\"\n",
    "\n",
    "    diff_df = pd.DataFrame(columns=mono_df.columns)\n",
    "\n",
    "    for i, row in mono_df.iterrows():\n",
    "        model = str(i).replace(\"-mono\", \"\")\n",
    "        pooling = model + \"-pooling\"\n",
    "\n",
    "        mono_row = mono_df.loc[i]\n",
    "        pool_row = pool_df.loc[pooling]\n",
    "\n",
    "        diff = mono_row - pool_row\n",
    "        diff_df.loc[model] = diff\n",
    "\n",
    "    return diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "155880da-76d4-4688-9140-57b14025deaa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "diff_sib = compare_mono_pool(sib_df, task='sib200')\n",
    "diff_xnli = compare_mono_pool(xnli_df, task='xnli')\n",
    "diff_wiki = compare_mono_pool(wiki_df, task='wikiann')\n",
    "\n",
    "diff_sib_avg = np.mean(diff_sib)\n",
    "diff_xnli_avg = np.mean(diff_xnli)\n",
    "diff_wiki_avg = np.mean(diff_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "691e5b2d-d34a-4cc1-b864-e7c3343c9d0b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "diff_df = pd.DataFrame(columns=diff_sib.columns)\n",
    "diff_df.loc['sib200'] = diff_sib_avg\n",
    "diff_df.loc['xnli'] = diff_xnli_avg\n",
    "diff_df.loc['wikiann'] = diff_wiki_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be8b76d9-edfc-4476-a5d9-27f4e3a8b8ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_data(diff_df, xticks_rotation=0, title='Difference in accuracy for merge methods (mono - pooling)', xlabel='Tasks', ylabel=('Accuracy mono - accuracy pooling'), save_path=IMAGE_DIR / \"mono-pooling-acc.png\", color_map='tab20', ylim=(-0.1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cde96cbc-24e9-4e38-bd02-d45a0dc26d51",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def plot_comparison_data(dfs, labels, title=None, xlabel='Models', ylabel='Values', xticks_rotation=45, ylim=None, save_path=None, colors=None):\n",
    "    \"\"\"\n",
    "    Plots a bar chart for the provided list of DataFrames with options to display customizable labels, configurable y-axis limits, and save the figure to a file.\n",
    "\n",
    "    Args:\n",
    "    dfs (list of pd.DataFrame): List of DataFrames containing the data to be plotted.\n",
    "    labels (list of str): Labels for each DataFrame, used for the legend.\n",
    "    title (str, optional): Title of the plot.\n",
    "    xlabel (str, optional): Label for the x-axis.\n",
    "    ylabel (str, optional): Label for the y-axis.\n",
    "    xticks_rotation (int, optional): Degrees of rotation for the x-tick labels.\n",
    "    ylim (tuple, optional): A tuple (ymin, ymax) setting the limits of the y-axis.\n",
    "    save_path (str, optional): Path to save the figure. If None, the figure is not saved.\n",
    "    colors (list of str, optional): Colors for each DataFrame's bars.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    # Number of dataframes and width of each bar\n",
    "    num_dfs = len(dfs)\n",
    "    bar_width = 0.8 / num_dfs  # Adjust the width based on the number of DataFrames\n",
    "\n",
    "    # Generate positions for each group of bars\n",
    "    indices = np.arange(len(dfs[0]))  # Assumes all dfs have the same length and index\n",
    "    \n",
    "    for i, df in enumerate(dfs):\n",
    "        pos = indices + i * bar_width\n",
    "        ax.bar(pos, df.iloc[:, 0], width=bar_width, label=labels[i], color=colors[i] if colors else None)\n",
    "    \n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xticks(indices + bar_width * (num_dfs - 1) / 2)\n",
    "    ax.set_xticklabels(dfs[0].index, rotation=xticks_rotation)\n",
    "    \n",
    "    if ylim:\n",
    "        ax.set_ylim(ylim)\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"Figure saved to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42c351dc-584f-439c-a57d-300dbe1ec64f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## CF comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e6c958f-f4c0-495c-badd-7c53ef84b48d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "xnli0 = filter_models(xnli_df, terms=['pooling', 'experiment', 'xnli', 'base'], contains=any, out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0e83d4a-e018-4431-817e-9c3786853ea8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "xnli0_wikisib = filter_models(xnli0, terms=['wikiann', 'sib'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe6681c1-fb0d-4323-b14e-9aa3006d67d5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_domains(name):\n",
    "    # Extract tasks and language codes from the name using regular expressions\n",
    "    match = re.match(r'(\\w+)_(\\w{2})--(\\w+)_(\\w{2})-.*', name)\n",
    "    if match:\n",
    "        task0 = match.group(1)\n",
    "        lang0 = match.group(2)\n",
    "        task1 = match.group(3)\n",
    "        lang1 = match.group(4)\n",
    "        return task0, task1, lang0, lang1\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def normalize_df(df):\n",
    "    for column in df.columns:\n",
    "        min_val = df[column].min()\n",
    "        max_val = df[column].max()\n",
    "        df[column] = (df[column] - min_val) / (max_val - min_val) if (max_val - min_val) != 0 else 0\n",
    "    return df\n",
    "\n",
    "def target_switch_data_2(\n",
    "    df,\n",
    "    eval_task,\n",
    "    languages = ['ar', 'de', 'el', 'es', 'fr', 'ru'],\n",
    "    merge = ['mono'],\n",
    "):\n",
    "    '''\n",
    "    switch and target data on 1 task, for provided models\n",
    "    '''\n",
    "    data = pd.DataFrame()\n",
    "    model_names = set(df.index)\n",
    "    print(model_names)\n",
    "    for model in model_names:\n",
    "        _, _, X, Y = extract_domains(model)\n",
    "        \n",
    "        target_langs = [lang for lang in languages if lang in [X, Y]]\n",
    "        non_target_langs = [lang for lang in languages if lang not in [X, Y]]\n",
    "\n",
    "        model_df = df.loc[model]\n",
    "\n",
    "        # Average the columns that fall under ft_domains and mix_domains together after normalizing\n",
    "        tl_avg = df.loc[model, target_langs].mean()\n",
    "        ntl_avg = df.loc[model, non_target_langs].mean()\n",
    "        \n",
    "        data.loc[model.replace(\"-mono\", \"\"), 'target_lang'] = tl_avg\n",
    "        data.loc[model.replace(\"-mono\", \"\"), 'non_target_lang'] = ntl_avg\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0e4aa3a-0d56-481f-8e02-64acb3d2eb6c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "xnli0_wikisib_TS = target_switch_data_2(xnli0_wikisib, eval_task='xnli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46f1b8c1-de05-460b-9cfc-85dd848dccb7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_data(xnli0_wikisib, show_averages=True, color_map='Pastel2', ylabel=\"Accuracy on XNLI\", title=\"Performance of WikiANN-SIB200 merged models averaged per language on XNLI.\", xticks_rotation=0, save_path= IMAGE_DIR / 'wikisib-on-xnli-per-lang.png', xlabel='Language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd0388de-ca8c-4dc0-9c9a-dd9deaaee3e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_data(xnli0_wikisib_TS, show_averages=False, xlabel=\"Model (mono merged)\", ylabel=\"Accuracy on XNLI\", title=\"Performance of WikiANN-SIB200 merged models on target and non-target languages on XNLI.\", xticks_rotation=35, color_map=\"tab20\", save_path= IMAGE_DIR / 'target-non-wikisib-on-xnli.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6b53254-1b42-43e6-b7dc-fe5b7a16059c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ft_sib0 = filter_models(sib_df, terms=['mono', 'pooling', 'experiment', 'sib', 'base'], contains=any, out=True)\n",
    "ft_xnli0 = filter_models(xnli_df, terms=['mono', 'pooling', 'experiment', 'xnli', 'base'], contains=any, out=True)\n",
    "ft_wikiann0 = filter_models(wiki_df, terms=['mono', 'pooling', 'experiment', 'wiki', 'base'], contains=any, out=True)\n",
    "\n",
    "bm_sib0 = filter_models(filter_models(sib_df, terms=['mono', 'base'], contains=all, out=False), terms=['sib'], out=True, contains=any)\n",
    "bm_xnli0 = filter_models(filter_models(xnli_df, terms=['mono', 'base'], contains=all, out=False), terms=['xnli'], out=True, contains=any)\n",
    "bm_wiki0 = filter_models(filter_models(wiki_df, terms=['mono', 'base'], contains=all, out=False), terms=['wiki'], out=True, contains=any)\n",
    "\n",
    "bm_sib0_xnli = filter_models(bm_sib0, terms=['xnli'])\n",
    "bm_sib0_wiki = filter_models(bm_sib0, terms=['wiki'])\n",
    "\n",
    "bm_xnli0_sib = filter_models(bm_xnli0, terms=['sib'])\n",
    "bm_xnli0_wiki = filter_models(bm_xnli0, terms=['wiki'])\n",
    "\n",
    "bm_wiki0_xnli = filter_models(bm_wiki0, terms=['xnli'])\n",
    "bm_wiki0_sib = filter_models(bm_wiki0, terms=['sib'])\n",
    "\n",
    "ft_sib0_xnli = filter_models(ft_sib0, terms=['xnli'])\n",
    "ft_sib0_wiki = filter_models(ft_sib0, terms=['wiki'])\n",
    "\n",
    "ft_xnli0_sib = filter_models(ft_xnli0, terms=['sib'])\n",
    "ft_xnli0_wiki = filter_models(ft_xnli0, terms=['wiki'])\n",
    "\n",
    "ft_wiki0_xnli = filter_models(ft_wikiann0, terms=['xnli'])\n",
    "ft_wiki0_sib = filter_models(ft_wikiann0, terms=['sib'])\n",
    "\n",
    "sib_base = sib_df.loc['base']\n",
    "xnli_base = xnli_df.loc['base']\n",
    "wiki_base = wiki_df.loc['base']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7959dd16-1db0-475c-9ec1-03d741fd6557",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_comparison_df(base_values, ft_wiki_mean, bm_wiki_mean, ft_xnli_mean, bm_xnli_mean, columns):\n",
    "    \"\"\"\n",
    "    Create a DataFrame to compare base values and filtered model means.\n",
    "\n",
    "    Parameters:\n",
    "    - base_values : pd.Series \n",
    "    - ft_wiki_mean : pd.Series\n",
    "    - bm_wiki_mean : pd.Series\n",
    "    - ft_xnli_mean : pd.Series\n",
    "    - bm_xnli_mean : pd.Series\n",
    "    - columns : list of str\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame\n",
    "    \"\"\"\n",
    "    index_labels = ['base', 'ft-wiki', 'base-ft-wiki', 'ft-xnli', 'xnli_avg']\n",
    "    data = {\n",
    "        'base': base_values,\n",
    "        'ft-wiki': ft_wiki_mean,\n",
    "        'base-ft-wiki': bm_wiki_mean,\n",
    "        'ft-xnli': ft_xnli_mean,\n",
    "        'xnli_avg': bm_xnli_mean\n",
    "    }\n",
    "    comparison_df = pd.DataFrame(data, index=index_labels, columns=columns)\n",
    "    \n",
    "    return comparison_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "164a41f3-3864-4f84-9063-71df825a3a22",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example DataFrame creation for each task\n",
    "columns = ['ar', 'de', 'el', 'es', 'fr', 'ru']\n",
    "\n",
    "# Assuming you have these base and mean values calculated or loaded\n",
    "zero_sib = create_comparison_df(sib_base, ft_sib0_wiki.mean(), bm_sib0_wiki.mean(), ft_sib0_xnli.mean(), bm_sib0_xnli.mean(), columns)\n",
    "zero_xnli = create_comparison_df(xnli_base, ft_xnli0_wiki.mean(), bm_xnli0_wiki.mean(), ft_xnli0_sib.mean(), bm_xnli0_sib.mean(), columns)\n",
    "zero_wikiann = create_comparison_df(wiki_base, ft_wiki0_xnli.mean(), ft_wiki0_sib.mean(), another_mean1, another_mean2, columns)  # Fill in the proper mean calculations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13ce9c26-2d90-4253-bb53-ec221eb60ceb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "columns = ['ar', 'de', 'el', 'es', 'fr', 'ru']\n",
    "index_labels = ['base', 'ft-wiki', 'base-ft-wiki', 'ft-xnli', 'xnli_avg']\n",
    "\n",
    "ft_wiki_mean = ft_sib0_wiki.mean()\n",
    "bm_wiki_mean = bm_sib0_wiki.mean()\n",
    "ft_xnli_mean = ft_sib0_xnli.mean()\n",
    "bm_xnli_mean = bm_sib0_xnli.mean()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "analysis",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
